{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## A Hacker's Guide to Having Your NYTimes Article Comments Noticed\n",
    "\n",
    "\n",
    "### The problem: predicting the number of upvotes ('recommendations') that a comment posted to an article on the [New York Times](www.nytimes.com) will receive. \n",
    "\n",
    "![Imgur](https://i.imgur.com/Vm9tAsj.png?1)\n",
    "\n",
    "Readers of the [Gray Lady](www.nytimes.com) are able to post comments on articles and react to the comments of others by either upvoting ('Recommend' button) or replying. For a comment-author, recommendations are desirable because they bring about more visibility - recommended comments float up to the top where they are seen by more readers and can receive even more upvotes. Once a comment 'snowballs' it can be seen by potentially millions of readers. Presumably we write comments because we want others to see them.\n",
    "\n",
    "I got curious about what makes some comments rise to the top while most others are completely ignored. [Aashita Kesarwani](https://www.kaggle.com/aashita https://www.kaggle.com/aashita) posted a cool dataset on [Kaggle](www.kaggle.com) of more than 2 million comments geared toward addressing this and similar questions. Be sure to check out the dataset [here](https://www.kaggle.com/aashita/nyt-comments) as well as her wonderful exploratory data analysis of it [here](https://www.kaggle.com/aashita/exploratory-data-analysis-of-comments-on-nyt/data). The data come from two time periods: Jan-May 2017 and Jan-April 2018 and contain features on both the comments (with the full raw text body of each comment) and the more than 9 thousand NYTimes articles the comments were responding to.\n",
    "\n",
    "I like this as a prediction task because it is challenging. Presumably what makes people upvote comments or posts, not just at the Times but also in other social media settings (Reddit, Twitter, FB, etc) is the _meaning_ of the comment - they find it helpful, or funny or simply agree with it and want others to see it too. Since we can't easily quantify 'meaning,' we'll have to rely on some feature engineering in order to get any traction with our predictions. The task is also challenging because we don't know much about the readers who are responding to comments and do not have the full text of the articles. Additionally, some comments are pretty short, so they are not easily amenable to a more complicated language model. After extracting what we can from the features already present in the dataset, we will have to wrangle useful information out of noisy and messy raw text - the body of the comments.\n",
    "\n",
    "The main point to consider here is that we need to set our expectations low, because this is no handwritten digit recognition exercise with 99%+ accuracy. Even a human scorer would probably not do well in terms of predicting upvotes. Consider these two comments, both made in responde to the same article:\n",
    "\n",
    "A. '_Everyone should have walked out.  Spicer could have talked to himself._'\n",
    "\n",
    "B. '_If people are \"alarmed\" and \"appalled\" that Trump did this, followed by his cronies justification of it, then they haven't been paying attention. I'm just surprised he took this long to do it. The story here, the one that people should actually be alarmed and appalled by is that the rest of the press stayed. Brietbart, One America, not so surprising but there is absolutely no excuse for rest to have shown so little respect for the one of the most important and defining features of America... The First Amendment, a free press. To echo Mr Kahn's question to President Trump...have you even read the constitution? Here, let me give you a head start... Amendment I: Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the Government for a redress of grievances._'\n",
    "\n",
    "Without any contextual knowledge, I would have guessed that the two comments would be roughly on par or the first one would receive fewer upvotes. They are generally similar in terms of the reaction to the article, though the second comment is longer and contains more information. The reality is quite different: comment A received over 10,000 upvotes and is the most upvoted comment in the entire dataset, while comment B got ... zero upvotes. \n",
    "\n",
    "If you are interested in the takeaways (and one very plausible explanation about the popularity of these two comments, it is not simply brevity!), skip right to the last section. In the sections that follow we will go through the traditional steps of classification, with an emphasis on feature engineering out of the numerical and text data.\n",
    "\n",
    "The original target variable here is a count variable of recommendations. For the artificial purpose of using classification algos and metrics, I will discretize it to four meaningful and roughly equal-sized categories. Since the largest of them is about 29%, this is our prediction baseline: if we simply picked that always, our classification would be accurate 29% of the time.\n",
    "\n",
    "Categories:\n",
    "1. None ~29%\n",
    "2. One or two ~29%\n",
    "3. Three to eight ~23%\n",
    "4. More than eight (up to tens of thousands) ~18%\n",
    "\n",
    "Naturally, you also choose to keep the original target variable (though cropping the right tail of the distribution might be a good idea due to how skewed it is) and rely on regression and metrics such as mean squared error. (In that case, it would probably be most appropriate to use a negative binomial model for the first simple fit, due to the count nature of the data and the fact that zero has meaning.)\n",
    "\n",
    "\n",
    "### Table of contents:\n",
    "1. [Data Loading & Preparation](#data)\n",
    "    1. [Load data files & combine](#dataloading)\n",
    "\t2. [Discretize **recommendations** (target)](#cut)\n",
    "\t3. [Turn categorical to dummies](#todummies)\n",
    "2. [Initial prediction](#initpredict)\n",
    "\t1. [Simple Multinomial Logistic](#logit)\n",
    "\t2. [A bag of classifiers](#classifiers)\n",
    "3. [Feature Engineering](#featureengineering)\n",
    "    1. [Features based on original variables](#originalvars)\n",
    "        1. [Replyupvotes](#reply)\n",
    "        2. [byline](#byline)\n",
    "        3. [Time](#time)\n",
    "    2. [Features based on raw text data](#textdata)\n",
    "        1. [A NYTimes vocabulary & IDF profile](#vocab)\n",
    "\t2. [Basic stats, sentiment analysis, spelling errors & part of speech](#kitchensink)\n",
    "\t3. [Text token features](#texttokens)\n",
    "4. [Training & Re-evaluation](#training)\n",
    "\t1. [Simple Multinomial Logistic](#finallogit)\n",
    "\t2. [A bag of classifiers](#finalclassifiers)\n",
    "5. [Takeaways](#tldr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Data loading <a name='dataloading'></a>\n",
    "\n",
    "First, let's prepare the data. We'll load almost all features present in the .csv files in their original shapes into a large dataframe, drop features that cannot be useful (too many missing cases) and convert the categorical features to dummies. This will enable us to do a first-cut prediction without  feature engineering - almost as if we know nothing about the dataset and are doing a blind prediction. 'Almost' because we will deliberately exclude one feature that is surely related to the target - the number of replies a comment has received (**replyCount**). We would expect this to be an effect (consequence), rather than a cause of the number of upvotes - upvoted comments are highly visible and therefore much more likely to receive replies.\n",
    "\n",
    "We will initially ignore the raw text features (body of comments and keywords of the article) but keep them for later. Finally, to speed up our work here, we will take a random sample of about 10% of the cases (sometimes called 'dev set'). \n",
    "\n",
    "Load libraries and already-downloaded data first. There are two separate sets of files, the first containing comments and comment-features and the second containing features about the articles. We read in all of the data, merge them into one Pandas Dataframe where each row is a comment and eliminate all duplicates. \n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# set a few options:\n",
    "sns.set(style='whitegrid')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth = 100\n",
    "%matplotlib inline\n",
    "# Kernel to predict upvotes ('recommendations' as target); will cut into intervals to turn this into a classification exercise\n",
    "\n",
    "# IDEAS for features:\n",
    "# Time of approval (earlier is better)\n",
    "# sentiment (positive-negative)\n",
    "# vocabulary sophistication!\n",
    "# origin/source\n",
    "# printPage\n",
    "# comment word count\n",
    "# article word count\n",
    "# average sentence length\n",
    "# maximum sentence length\n",
    "# is a reply - using (inReplyTo) a popular comment!\n",
    "# relevance: # of words in article that are in comment\n",
    "# day of the week and hour comment was published?\n",
    "# day of the week the original article was published\n",
    "# nltk - use sentence splitter and tokenizer? (for average sentence length)\n",
    "# editorsSelection - selected by editor or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "1. Load data files & combine <a name='dataloading'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9335 entries, 0 to 948\n",
      "Data columns (total 16 columns):\n",
      "abstract            167 non-null object\n",
      "articleID           9335 non-null object\n",
      "articleWordCount    9335 non-null int64\n",
      "byline              9335 non-null object\n",
      "documentType        9335 non-null object\n",
      "headline            9335 non-null object\n",
      "keywords            9335 non-null object\n",
      "multimedia          9335 non-null int64\n",
      "newDesk             9335 non-null object\n",
      "printPage           9335 non-null int64\n",
      "pubDate             9335 non-null object\n",
      "sectionName         9335 non-null object\n",
      "snippet             9335 non-null object\n",
      "source              9335 non-null object\n",
      "typeOfMaterial      9335 non-null object\n",
      "webURL              9335 non-null object\n",
      "dtypes: int64(3), object(13)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9335 entries, 0 to 948\n",
      "Data columns (total 7 columns):\n",
      "articleID       9335 non-null object\n",
      "byline          9335 non-null object\n",
      "headline        9335 non-null object\n",
      "keywords        9335 non-null object\n",
      "pubDate         9335 non-null object\n",
      "snippet         9335 non-null object\n",
      "documentType    9335 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 583.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# small function to read all .csv files containing a string\n",
    "def read_files(string='Articles', path='./Data/'):\n",
    "    '''Read .csv files starting with string and concat them into a pd.DataFrame'''\n",
    "    files = glob.glob(path + string + '*.csv')\n",
    "    list_dfs = []\n",
    "    for csv in files:\n",
    "        df_ = pd.read_csv(csv)\n",
    "        list_dfs.append(df_)\n",
    "    return pd.concat(list_dfs)\n",
    "\n",
    "\n",
    "# read in the articles files\n",
    "df_articles = read_files('Articles')\n",
    "\n",
    "# brief look inside:\n",
    "print(df_articles.info())\n",
    "\n",
    "# Leave only features which are not already present in the comments data, do not have too many missing values and could potentially be useful (poked around a bit)\n",
    "useful_columns = ['articleID',\n",
    "                  'byline',\n",
    "                  'headline',\n",
    "                  'keywords',\n",
    "                  'pubDate',\n",
    "                  'snippet',\n",
    "                  'documentType'\n",
    "                  ]\n",
    "\n",
    "df_articles = df_articles[useful_columns]\n",
    "print(df_articles.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Do the same for the comments files, merge the two into one DataFrame and drop all duplicates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2176364 entries, 0 to 264923\n",
      "Data columns (total 34 columns):\n",
      "approveDate              int64\n",
      "articleID                object\n",
      "articleWordCount         float64\n",
      "commentBody              object\n",
      "commentID                float64\n",
      "commentSequence          float64\n",
      "commentTitle             object\n",
      "commentType              object\n",
      "createDate               float64\n",
      "depth                    float64\n",
      "editorsSelection         int64\n",
      "inReplyTo                float64\n",
      "newDesk                  object\n",
      "parentID                 float64\n",
      "parentUserDisplayName    object\n",
      "permID                   object\n",
      "picURL                   object\n",
      "printPage                float64\n",
      "recommendations          float64\n",
      "recommendedFlag          float64\n",
      "replyCount               float64\n",
      "reportAbuseFlag          float64\n",
      "sectionName              object\n",
      "sharing                  int64\n",
      "status                   object\n",
      "timespeople              float64\n",
      "trusted                  float64\n",
      "typeOfMaterial           object\n",
      "updateDate               int64\n",
      "userDisplayName          object\n",
      "userID                   float64\n",
      "userLocation             object\n",
      "userTitle                object\n",
      "userURL                  object\n",
      "dtypes: float64(15), int64(4), object(15)\n",
      "memory usage: 581.2+ MB\n",
      "None\n",
      "(2086862, 40)\n"
     ]
    }
   ],
   "source": [
    "# read in the Comments files (large-ish, 500M+)\n",
    "df_comments = read_files('Comments')\n",
    "print(df_comments.info())\n",
    "# join the two by articleID; drop the comments that are not associated with articles\n",
    "df = pd.merge(df_comments, df_articles, how='inner',\n",
    "              on='articleID')\n",
    "# drop duplicate comments\n",
    "df.drop_duplicates(subset='commentID', inplace=True)\n",
    "print(df.shape)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Count missing values and drop the features if there are too many (> 1 mln) missing. We can come back later and try to extract useful information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approveDate                    0\n",
      "articleID                      0\n",
      "articleWordCount               0\n",
      "commentBody                    0\n",
      "commentID                      0\n",
      "commentSequence                0\n",
      "commentTitle               73979\n",
      "commentType                    0\n",
      "createDate                     0\n",
      "depth                          0\n",
      "editorsSelection               0\n",
      "inReplyTo                      0\n",
      "newDesk                        0\n",
      "parentID                       0\n",
      "parentUserDisplayName    1528830\n",
      "permID                        22\n",
      "picURL                         0\n",
      "printPage                      0\n",
      "recommendations                0\n",
      "recommendedFlag          2086862\n",
      "replyCount                     0\n",
      "reportAbuseFlag          2086862\n",
      "sectionName               149613\n",
      "sharing                        0\n",
      "status                         0\n",
      "timespeople                    0\n",
      "trusted                        0\n",
      "typeOfMaterial                 0\n",
      "updateDate                     0\n",
      "userDisplayName              641\n",
      "userID                         0\n",
      "userLocation                 480\n",
      "userTitle                2086552\n",
      "userURL                  2086841\n",
      "byline                         0\n",
      "headline                       0\n",
      "keywords                       0\n",
      "pubDate                        0\n",
      "snippet                        0\n",
      "documentType                   0\n",
      "dtype: int64\n",
      "(2086862, 35)\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "\n",
    "# several features are missing for most or all cases, drop them\n",
    "df = df.loc[:, df.isnull().sum() < 10**6]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Discretizing the target variable <a name='cut'></a>\n",
    "\n",
    "Next, look at the target (**Recommendations**) and turn it into four categories for classification. The original variable is a count heavily slanted toward zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f841f359668>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target is recommendations, heavily slanted distribution\n",
    "sns.distplot(df.recommendations.loc[df.recommendations < 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Take a look at the bottom of the distribution, dominated by zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    385013\n",
      "1.0    278544\n",
      "2.0    209162\n",
      "3.0    162014\n",
      "4.0    127792\n",
      "5.0    103044\n",
      "6.0     84626\n",
      "7.0     71178\n",
      "8.0     60258\n",
      "9.0     51066\n",
      "Name: recommendations, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.recommendations.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "and the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1144824     7709.0\n",
       "1689041     7938.0\n",
       "1336725     8124.0\n",
       "492845      8125.0\n",
       "100287      8160.0\n",
       "1336745     8514.0\n",
       "174774      8639.0\n",
       "1936249     8713.0\n",
       "1095256     9279.0\n",
       "174791     10472.0\n",
       "Name: recommendations, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.recommendations.sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So the vast majority have fewer than 15 upvotes and there are only a handful with over 6000. Let's slice the variable into four roughly equal sized categories, and rename it to **recs**. We also change it to an _int_ that ranges 1 to 4 in order to make throwing it into a variety of models a bit easier (including multinomial logistic regression). (The alternative is a labeled categorical variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9)         0.292\n",
      "[9, 100000)    0.290\n",
      "[1, 3)         0.234\n",
      "[0, 1)         0.184\n",
      "Name: reclabels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# cut the interval into 4 bins\n",
    "df['reclabels'] = pd.cut(df.recommendations, bins=(0, 1, 3, 9, 100000),\n",
    "                    include_lowest=True, right=False)\n",
    "print(df.reclabels.value_counts(normalize=True).round(3))\n",
    "# change it to int\n",
    "df['recs'] = df.reclabels.cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The distribution of the new categorical variable looks much more balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8415731780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFdNJREFUeJzt3X+Q3fVd7/HnEijFHzRpq5FJMgO28d2JGaEsknjr3FtB0wUZg/dSBLUJyKV/QFs66i20FydzKfTGX20zShk7kLJxaiGltERn6TZDq73eaWhYbkVbeGuMMEkEoiRAK7ZM8Nw/ziewruecHLKfc07OyfMxc2a/3/f3x+ez38ny4vv5fva7Y41GA0mSajph0B2QJI0ew0WSVJ3hIkmqznCRJFVnuEiSqjtx0B04VszMzDhtTpKOwvj4+NjcmuEyy/j4+KC7IElDZWZmpmXdYTFJUnWGiySpOsNFklSd4SJJqs5wkSRVZ7hIkqozXCRJ1RkukqTqDBdJUnU9/Q39iFgI3A6sBBrArwEJ3A2cDjwOXJqZByNiDNgEXAi8AFyRmQ+X86wHbiynvTkzJ0t9HLgTOAWYAq7LzEZEvL5VG738XqVBmlp35aC7cMy4cMunBt0F0fvXv2wCvpiZl0TEa4DvAz4EPJCZGyPiBuAG4HrgAmB5+awCbgNWlaDYAJxDM6BmImJbCYvbgKuBB2mGywRwfzlnqzYkqaOP/M/PDroLx4wP3fLOoz62Z8NiEfE64D8DdwBk5ouZ+SywFpgsu00CF5fltcCWzGxk5g5gYUScBrwD2J6ZB0qgbAcmyrZTM3NHZjaALXPO1aoNSVIf9PLO5Qzgn4BPRcSZwAxwHbA4M58s+zwFLC7LS4A9s47fW2qd6ntb1OnQRkftXsAmaXj4c1zPfK5lL8PlROBs4L2Z+WBEbKI5PPWy8nykp6+6fzVt+FZkDaupQXfgGDLfn+Ppe3dX6snw6+ZaDuKtyHuBvZn5YFm/h2bYPF2GtChf95ft+4Bls45fWmqd6ktb1OnQhiSpD3oWLpn5FLAnIqKUzge+BWwD1pfaeuC+srwNWBcRYxGxGniuDG1NA2siYlFELALWANNl2/MRsbrMNFs351yt2pAk9UGvZ4u9F/h0mSm2G7iSZqBtjYirgCeAS8u+UzSnIe+iORX5SoDMPBARHwZ2lv1uyswDZfkaXpmKfH/5AGxs04YkqQ96Gi6Z+Q2aU4jnOr/Fvg3g2jbn2QxsblF/iObv0MytP9OqDUlSf/gb+pKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6k7s5ckj4nHg28BLwKHMPCciXg/cDZwOPA5cmpkHI2IM2ARcCLwAXJGZD5fzrAduLKe9OTMnS30cuBM4BZgCrsvMRrs2evm9SpJe0Y87l5/JzLMy85yyfgPwQGYuBx4o6wAXAMvL593AbQAlKDYAq4BzgQ0Rsagccxtw9azjJo7QhiSpDwYxLLYWmCzLk8DFs+pbMrORmTuAhRFxGvAOYHtmHih3H9uBibLt1MzckZkNYMucc7VqQ5LUBz0dFgMawJciogH8UWZ+ElicmU+W7U8Bi8vyEmDPrGP3llqn+t4WdTq00dHMzEw3u0k6hvlzXM98rmWvw+WnM3NfRPwwsD0iHpu9sTwfafSyA6+mjfHx8V52ReqZqUF34Bgy35/j6Xt3V+rJ8OvmWrYLoJ4Oi2XmvvJ1P/B5ms9Mni5DWpSv+8vu+4Blsw5fWmqd6ktb1OnQhiSpD3oWLhHx/RHxg4eXgTXA3wDbgPVlt/XAfWV5G7AuIsYiYjXwXBnamgbWRMSi8iB/DTBdtj0fEavLTLN1c87Vqg1JUh/0clhsMfD5iDjczp9k5hcjYiewNSKuAp4ALi37T9GchryL5lTkKwEy80BEfBjYWfa7KTMPlOVreGUq8v3lA7CxTRs6RlzxqesG3YVjxp1Xbhp0F6TqehYumbkbOLNF/Rng/Bb1BnBtm3NtBja3qD8ErOy2DUlSf/gb+pKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6k7sdQMRsQB4CNiXmRdFxBnAXcAbgBngXZn5YkScDGwBxoFngF/KzMfLOT4IXAW8BLwvM6dLfQLYBCwAbs/MjaXeso1ef6+SpKZ+3LlcBzw6a/23gY9l5puBgzRDg/L1YKl/rOxHRKwALgN+HJgAPhERC0po3QpcAKwALi/7dmpDktQHPQ2XiFgK/Dxwe1kfA84D7im7TAIXl+W1ZZ2y/fyy/1rgrsz8Xmb+A7ALOLd8dmXm7nJXchew9ghtSJL6oNfDYh8HPgD8YFl/A/BsZh4q63uBJWV5CbAHIDMPRcRzZf8lwI5Z55x9zJ459VVHaKOjmZmZ7r4rqSL/3dXl9axnPteyZ+ESERcB+zNzJiLe3qt2ahofHx90F44fj2wZdA+OGTX+3U1V6MeomO/1nL53d6WeDL9urmW7AOrlsNjbgF+IiMdpDlmdR/Ph+8KIOBxqS4F9ZXkfsAygbH8dzQf7L9fnHNOu/kyHNiRJfdCzcMnMD2bm0sw8neYD+S9n5q8AXwEuKbutB+4ry9vKOmX7lzOzUeqXRcTJZRbYcuDrwE5geUScERGvKW1sK8e0a0OS1AeD+D2X64Ffj4hdNJ+P3FHqdwBvKPVfB24AyMxvAluBbwFfBK7NzJfKM5X3ANM0Z6NtLft2akOS1Ac9/z0XgMz8c+DPy/JumjO95u7zXeCdbY6/BbilRX2KFsPN7dqYj1/+wKdrnm6o/cnv/MqguyDpGOdv6EuSqjNcJEnVGS6SpOoMF0lSdYaLJKk6w0WSVJ3hIkmqznCRJFXXVbhExNZuapIkQfd3Lm9uUXtLzY5IkkZHx9e/RMTVwLuBH4uIr8/a9Doge9kxSdLwOtK7xb4E/B3wh8D/mFV/HnikV52SJA23juGSmU8ATwAr+9MdSdIo6OqtyBERwI3Am2Yfk5lV3zwsSRoN3b5y/y7gs8CngJd61x1J0ijoNlxOyMyP9LQnkqSR0e1U5K9FxE/0tCeSpJHR7Z3LKuDKiEjgu4eLPnORJLXSbbi8v6e9kCSNlK7CJTP/otcdkSSNjm6nIu8EGnPrDotJklrpdljsN2ctvxa4HPjH+t2RJI2CoxoWi4gvAX/Zkx5Jkobe0f49l1OBH6nZEUnS6DiaZy4nAD8K/H6vOiVJGm5H88zlELA7M5/sdEBEvBb4KnByaeeezNwQEWfQfJ3MG4AZ4F2Z+WJEnAxsAcaBZ4BfyszHy7k+CFxF89Uz78vM6VKfADYBC4DbM3Njqbdso8vvVZI0T10Ni5VnLv8X+GfgWeCfujjse8B5mXkmcBYwERGrgd8GPpaZbwYO0gwNyteDpf6xsh8RsQK4DPhxYAL4REQsiIgFwK3ABcAK4PKyLx3akCT1Qbd/5vgc4O+BzwNfAP4uIs7udExmNjLzO2X1pPJpAOcB95T6JHBxWV5b1inbz4+IsVK/KzO/l5n/AOwCzi2fXZm5u9yV3AWsLce0a0OS1AfdDottAn4tMx8AiIjzgD8A3tbpoHJ3MUPzzyTfSjOgns3MQ2WXvcCSsrwE2AOQmYci4jmaw1pLgB2zTjv7mD1z6qvKMe3a6GhmZqab3Y57Xqe6vJ51eT3rmc+17DZcvv9wsABk5pcj4qNHOigzXwLOioiFNO963nJ03eyP8fHx9hvvfqx/HTnGdbxO3Xpky/zPMSJqXM+pCv0YFfO9ntP37q7Uk+HXzbVsF0DdTkV+ISLefnglIv4L8EKXx5KZzwJfAX4KWBgRh0NtKbCvLO8DlpXznwi8juaD/Zfrc45pV3+mQxuSpD7oNlzeB0xGxN9GxN/SfI7x3k4HRMQPlTsWIuIU4OeAR2mGzCVlt/XAfWV5W1mnbP9yZjZK/bKIOLnMAlsOfB3YCSyPiDMi4jU0H/pvK8e0a0OS1AfdDostBH4S+OGyvh9YeYRjTqMZSAtohtjWzPyziPgWcFdE3Az8P+COsv8dwB9HxC7gAM2wIDO/GRFbgW/RnAZ9bRluIyLeA0zTnIq8OTO/Wc51fZs2JEl90G24/C5wdmbuB4iIE4DfA9rOGMvMR4C3tqjvpjnTa279u8A725zrFuCWFvUpWgw3t2tDktQf3Q6LjZXhJgAy899o3i1IkvQfdBsu346IVYdXyvK/9KZLkqRh1+2w2AeAL0TE4WcaK4D/2psuSZKGXbev3P9aebXKT5XS1zLzYO+6JUkaZt3euVDCxN/VkiQd0dH+PRdJktoyXCRJ1RkukqTqDBdJUnWGiySpOsNFklSd4SJJqs5wkSRVZ7hIkqozXCRJ1RkukqTqDBdJUnWGiySpOsNFklSd4SJJqs5wkSRVZ7hIkqozXCRJ1RkukqTqDBdJUnUn9urEEbEM2AIsBhrAJzNzU0S8HrgbOB14HLg0Mw9GxBiwCbgQeAG4IjMfLudaD9xYTn1zZk6W+jhwJ3AKMAVcl5mNdm306nuVJP17vbxzOQT8RmauAFYD10bECuAG4IHMXA48UNYBLgCWl8+7gdsASlBsAFYB5wIbImJROeY24OpZx02Uers2JEl90LNwycwnD995ZOa3gUeBJcBaYLLsNglcXJbXAlsys5GZO4CFEXEa8A5ge2YeKHcf24GJsu3UzNyRmQ2ad0mzz9WqDUlSH/RsWGy2iDgdeCvwILA4M58sm56iOWwGzeDZM+uwvaXWqb63RZ0ObXQ0MzPTzW7HPa9TXV7Purye9cznWvY8XCLiB4DPAe/PzOcj4uVt5flIo5ftv5o2xsfH22+8+7FaXRp6Ha9Ttx7ZMv9zjIga13OqQj9GxXyv5/S9uyv1ZPh1cy3bBVBPZ4tFxEk0g+XTmXlvKT9dhrQoX/eX+j5g2azDl5Zap/rSFvVObUiS+qBn4VJmf90BPJqZH521aRuwviyvB+6bVV8XEWMRsRp4rgxtTQNrImJReZC/Bpgu256PiNWlrXVzztWqDUlSH/RyWOxtwLuAv46Ib5Tah4CNwNaIuAp4Ari0bJuiOQ15F82pyFcCZOaBiPgwsLPsd1NmHijL1/DKVOT7y4cObUiS+qBn4ZKZfwmMtdl8fov9G8C1bc61Gdjcov4QsLJF/ZlWbUiS+sPf0JckVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVWe4SJKqM1wkSdUZLpKk6gwXSVJ1hoskqTrDRZJUneEiSarOcJEkVXdir04cEZuBi4D9mbmy1F4P3A2cDjwOXJqZByNiDNgEXAi8AFyRmQ+XY9YDN5bT3pyZk6U+DtwJnAJMAddlZqNdG736PiVJ/1Ev71zuBCbm1G4AHsjM5cADZR3gAmB5+bwbuA1eDqMNwCrgXGBDRCwqx9wGXD3ruIkjtCFJ6pOehUtmfhU4MKe8Fpgsy5PAxbPqWzKzkZk7gIURcRrwDmB7Zh4odx/bgYmy7dTM3JGZDWDLnHO1akOS1Cc9GxZrY3FmPlmWnwIWl+UlwJ5Z++0ttU71vS3qndo4opmZmW53Pa55neryetbl9axnPtey3+HysvJ8pHEstTE+Pt5+492P1ejSSOh4nbr1yJb5n2NE1LieUxX6MSrmez2n791dqSfDr5tr2S6A+j1b7OkypEX5ur/U9wHLZu23tNQ61Ze2qHdqQ5LUJ/0Ol23A+rK8HrhvVn1dRIxFxGrguTK0NQ2siYhF5UH+GmC6bHs+IlaXmWbr5pyrVRuSpD7p5VTkzwBvB94YEXtpzvraCGyNiKuAJ4BLy+5TNKch76I5FflKgMw8EBEfBnaW/W7KzMOTBK7hlanI95cPHdqQJPVJz8IlMy9vs+n8Fvs2gGvbnGczsLlF/SFgZYv6M63akCT1j7+hL0mqznCRJFVnuEiSqjNcJEnVGS6SpOoMF0lSdYaLJKk6w0WSVJ3hIkmqznCRJFVnuEiSqjNcJEnVGS6SpOoMF0lSdYaLJKk6w0WSVJ3hIkmqznCRJFVnuEiSqjNcJEnVGS6SpOoMF0lSdYaLJKk6w0WSVJ3hIkmq7sRBd6BXImIC2AQsAG7PzI0D7pIkHTdG8s4lIhYAtwIXACuAyyNixWB7JUnHj5EMF+BcYFdm7s7MF4G7gLUD7pMkHTfGGo3GoPtQXURcAkxk5n8v6+8CVmXme9odMzMzM3oXQpL6YHx8fGxubWSfubxarS6OJOnojOqw2D5g2az1paUmSeqDUb1z2Qksj4gzaIbKZcAvD7ZLknT8GMk7l8w8BLwHmAYeBbZm5jcH2ytJOn6M5AN9SdJgjeSdiyRpsAwXSVJ1o/pAf+T4Opt6ImIzcBGwPzNXDro/wy4ilgFbgMVAA/hkZm4abK+GU0S8FvgqcDLN/z7fk5kbBturo+OdyxDwdTbV3QlMDLoTI+QQ8BuZuQJYDVzrv8+j9j3gvMw8EzgLmIiI1QPu01ExXIaDr7OpKDO/ChwYdD9GRWY+mZkPl+Vv05yhuWSwvRpOmdnIzO+U1ZPKZyhnXTksNhyWAHtmre8FVg2oL1JbEXE68FbgwQF3ZWiVkYoZ4M3ArZk5lNfSOxdJVUTEDwCfA96fmc8Puj/DKjNfysyzaL5Z5NyIGMrngobLcPB1NjqmRcRJNIPl05l576D7Mwoy81ngKwzp80HDZTi8/DqbiHgNzdfZbBtwnyQAImIMuAN4NDM/Ouj+DLOI+KGIWFiWTwF+DnhssL06Ov6G/pCIiAuBj9Ocirw5M28ZcJeGVkR8Bng78EbgaWBDZt4x0E4NsYj4aeD/AH8N/FspfygzpwbXq+EUET8BTNL8OT+B5qurbhpsr46O4SJJqs5hMUlSdYaLJKk6w0WSVJ3hIkmqznCRJFVnuEiSqjNcpGNARPieP40U/0FLAxIRDeB/AT8PfBH4rYi4HvhvNH829wFXZ+ZT5c0MH6H5KpCXgN2Z+YsR8Z+AP6T5P4onATdn5mf6/91I/553LtJg/Wtm/mRm/lZE/CrwJmB1Zp4NTAG/X/b7IPCjwNnlb31cXerXA79bXnS4Eri/v92XWvPORRqsyVnLvwCcAzwcEdD8+XyubLuI5h/kehEgM/+51L8C3BgRbwK2D+vr2TV6DBdpsL4za3mM5rDW5m4PzsyPR8SfAj8L/EFEfCkzb6zdSenVclhMOnZsA66JiEUAEXFyRJxZtv0Z8P7y7IWIeGP5+mOZ+feZ+UfAJpp/tVQaOO9cpGNEZv5xCY2/KMNiJwCfAP4K2Aj8b+AbEfEisAu4BHhfRPwM8CLNv7/+3kH0XZrLtyJLkqpzWEySVJ3hIkmqznCRJFVnuEiSqjNcJEnVGS6SpOoMF0lSdf8fe+AUm7GC4N4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.recs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Turn categorical to dummies <a name='todummies'></a>\n",
    "\n",
    "We'll do it using a wrapper around the useful Pandas function **get_dummies**. (There is an analogous function in Sklearn.) Note the fact that we drop one (usually the first) category in order to prevent colinearity issues (at least in the case of Logistic Regression for example). Look at non-numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2086862 entries, 0 to 2086861\n",
      "Data columns (total 18 columns):\n",
      "articleID          object\n",
      "commentBody        object\n",
      "commentTitle       object\n",
      "commentType        object\n",
      "newDesk            object\n",
      "permID             object\n",
      "picURL             object\n",
      "sectionName        object\n",
      "status             object\n",
      "typeOfMaterial     object\n",
      "userDisplayName    object\n",
      "userLocation       object\n",
      "byline             object\n",
      "headline           object\n",
      "keywords           object\n",
      "pubDate            object\n",
      "snippet            object\n",
      "documentType       object\n",
      "dtypes: object(18)\n",
      "memory usage: 286.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.select_dtypes(include='object').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Of these we'll pick the potentially useful ones and leave the raw text features (**byline**, **headline**, **keywords**, and **commentBody**) for now. One of the categorical variables in the dataset (whether or not the comment has been recommended by the NYTimes staff, **editorsSelection**) is really coded as _int_, so we include it here. We'll also ignore several features (such as **userLocation** and **userDisplayName**) for now, which contain quite a bit of noise, though they could be utilized later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2086862, 121)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2086862 entries, 0 to 2086861\n",
      "Columns: 121 entries, editorsSelection__1 to documentType__blogpost\n",
      "dtypes: uint8(121)\n",
      "memory usage: 240.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding function for categorical\n",
    "def OneHotEncoding(list_of_variables, data=df):\n",
    "    '''One-hot-encodes a list of string (categorical) variables from a dataframe\n",
    "    into binary features for modeling. It drops the last category to prevent colinearity problems (reference category).\n",
    "    Outputs a dataframe the same number of rows as original df.'''\n",
    "    new_df = []\n",
    "    for var in list_of_variables:\n",
    "        new_df.append(pd.get_dummies(\n",
    "            df[var],\n",
    "            drop_first=True,\n",
    "            prefix=(var + '_')))\n",
    "    return pd.concat(new_df, axis=1)\n",
    "\n",
    "# \n",
    "list_of_categorical = ['editorsSelection',\n",
    "                       'newDesk',\n",
    "                       'sectionName',\n",
    "                       'typeOfMaterial',\n",
    "                       'commentType',\n",
    "                       'documentType'\n",
    "]\n",
    "\n",
    "\n",
    "df_temp = OneHotEncoding(list_of_categorical, data=df)\n",
    "print(df_temp.shape)\n",
    "print(df_temp.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And let's grab the numeric features which could be meaningful and combine into a new dataframe. These are most if not all of the numerical features which could be related to the target: length measured in words of the article, page of the newspaper it appeared on, whether the author of the comments is a member of the NYTimes staff and so on. Again, we will not include the number of responses a comment has received as that should be a consequence, rather than a predictor of upvotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2086862, 129)\n"
     ]
    }
   ],
   "source": [
    "list_of_numeric = ['approveDate',\n",
    "                   'articleWordCount',\n",
    "                   'depth',\n",
    "                   'printPage',\n",
    "                   'timespeople',\n",
    "                   'trusted',\n",
    "                   'sharing',\n",
    "                   'recs'\n",
    "]\n",
    "# combine the two types of features\n",
    "X_full = pd.concat([df_temp, df[list_of_numeric]], axis=1)\n",
    "X_full.reset_index(drop=True, inplace=True)\n",
    "del df_temp\n",
    "print(X_full.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "One last housekeeping chore: the raw text of the comment bodies, which we will use later, contain some html markup which we should remove (as suggested by the original author of the dataset). We do that with a simple wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# This list of artfects to remove is from the original dataset exploration post by Aashita Kesarwani https://www.kaggle.com/aashita/exploratory-data-analysis-of-comments-on-nyt/code\n",
    "replacements = {\"(<br/>)\": \"\",\n",
    "                \"(<br/>)\": \"\",\n",
    "                '(<a).*(>).*(</a>)': '',\n",
    "                '(&amp)': '',\n",
    "                '(&gt)': '',\n",
    "                '(&gt)': '',\n",
    "                '(&lt)': '',\n",
    "                '(\\xa0)': ' ',\n",
    "                }\n",
    "\n",
    "\n",
    "def preprocess(commentBody):\n",
    "    '''Function to clean up the body of comments by removing artefacts'''\n",
    "    for pattern, replacement in replacements.items():\n",
    "        commentBody = commentBody.str.replace(pattern, replacement)\n",
    "    return commentBody\n",
    "\n",
    "\n",
    "# clean up the comments\n",
    "df['commentBody'] = preprocess(df.commentBody)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To wrap up the data loading, let's create a smaller dev set (only 5% or about 100K comments) that we can play with without waiting for long executions. We'll keep the index so that we may pull more features from the full dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 104343 entries, 454762 to 846424\n",
      "Columns: 129 entries, editorsSelection__1 to recs\n",
      "dtypes: float64(5), int64(2), int8(1), uint8(121)\n",
      "memory usage: 18.5 MB\n",
      "None\n",
      "(104343, 129)\n"
     ]
    }
   ],
   "source": [
    "dev_set_size = .05\n",
    "dev_set_index = X_full.sample(frac=dev_set_size, random_state=12).index\n",
    "X = X_full.loc[dev_set_index, :]\n",
    "print(X.info())\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Initial prediction <a name='initpredict'></a>\n",
    "\n",
    "First, let's load the libraries we will use for this and try to fit a simple multinomial logistic model. To fit the logistic regression we will need to remove features that have no variance (rare categories that end up with no examples because of our reduced sample, for example) or are extremely highly correlated with other features. Both of these pose problems for the simple logistic model (extreme or perfect multicolinearity) and are generally not going to contribute much to the prediction anyway.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import statsmodels.api as st\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost\n",
    "scaler_standard = StandardScaler()\n",
    "################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Next, let's create a simple function that reports the highest correlations within a dataset. We need it in order to eliminate features that are highly correlated and we'll be using it during the feature creation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sectionName__Book Review  newDesk__BookReview             0.995955\n",
       "typeOfMaterial__Letter    newDesk__Letters                0.993879\n",
       "commentType__userReply    depth                           0.991123\n",
       "typeOfMaterial__Op-Ed     newDesk__OpEd                   0.968098\n",
       "newDesk__Editorial        typeOfMaterial__Editorial       0.944538\n",
       "sectionName__The Daily    newDesk__Podcasts               0.942805\n",
       "typeOfMaterial__Op-Ed     typeOfMaterial__News           -0.812508\n",
       "newDesk__OpEd             typeOfMaterial__News           -0.807691\n",
       "newDesk__SpecialSections  sectionName__Retirement         0.757212\n",
       "newDesk__Unknown          documentType__blogpost          0.725573\n",
       "typeOfMaterial__Blog      newDesk__Unknown                0.725573\n",
       "newDesk__Obits            typeOfMaterial__Obituary ...    0.687075\n",
       "sectionName__Television   newDesk__Culture                0.617647\n",
       "sectionName__Family       newDesk__Well                   0.571447\n",
       "articleWordCount          newDesk__Magazine               0.565074\n",
       "sectionName__Unknown      sectionName__Politics          -0.558965\n",
       "sectionName__Politics     newDesk__Washington             0.534285\n",
       "newDesk__National         sectionName__Politics           0.523534\n",
       "sectionName__Europe       newDesk__Foreign                0.492641\n",
       "newDesk__Unknown          sectionName__Room For Deb...    0.481408\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_correlations(df, n=20):\n",
    "    '''Display top n correlations less than 1 from a pd.DataFrame'''\n",
    "    original_names = df.columns\n",
    "    df.columns = [str(x)[:25] + '...' if len(x) >\n",
    "                  25 else x for x in original_names]\n",
    "    corrs = df.corr().unstack()\n",
    "    corrs = corrs.reindex(corrs.abs().sort_values(ascending=False).index)\n",
    "    corrs = corrs[corrs != 1]\n",
    "    df.columns = original_names\n",
    "    return corrs.iloc[::2].head(n)\n",
    "top_correlations(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Evidently many of the section and news desk categories largely overlap. Also, the feature **depth** which measures whether a comment is a reply to another comment or a reply to a reply, etc (level 1 is an original comment, level 2 is a response and so on) unsurprisingly overlaps with the 'userReply' value of **commentType**. For now we'll solve this be eliminating one of each pair, preferring to keep the more informative feature **depth** and eliminating all **newDesk** features, as the original variable has more missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sectionName__Politics         sectionName__Unknown           -0.558965\n",
       "typeOfMaterial__News          sectionName__Politics           0.469612\n",
       "                              printPage                      -0.443820\n",
       "sectionName__Unknown          printPage                       0.391061\n",
       "                              typeOfMaterial__News           -0.389670\n",
       "sectionName__Australia        typeOfMaterial__Biography       0.388851\n",
       "depth                         recs                           -0.375916\n",
       "typeOfMaterial__Blog          sectionName__Room For Deb...    0.349296\n",
       "documentType__blogpost        sectionName__Room For Deb...    0.349296\n",
       "sectionName__Television       typeOfMaterial__Review          0.337910\n",
       "printPage                     typeOfMaterial__Editorial       0.304141\n",
       "typeOfMaterial__Editorial     typeOfMaterial__News           -0.300170\n",
       "articleWordCount              typeOfMaterial__News            0.299543\n",
       "sectionName__Sunday Revie...  typeOfMaterial__News           -0.294907\n",
       "sectionName__Book Review      typeOfMaterial__Interview       0.284979\n",
       "sectionName__Politics         printPage                      -0.284216\n",
       "sectionName__Unknown          sectionName__Sunday Revie...   -0.278649\n",
       "sectionName__Book Review      typeOfMaterial__Review          0.277533\n",
       "timespeople                   approveDate                    -0.213252\n",
       "sectionName__Unknown          typeOfMaterial__Editorial       0.180971\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(['commentType__userReply',\n",
    "        'typeOfMaterial__Op-Ed'],        \n",
    "       inplace=True, axis=1)\n",
    "X.drop(list(X.filter(regex='newDesk')), inplace=True, axis=1)\n",
    "top_correlations(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "First fit, Multinomial Logistic: <a name='logit'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We separate the target and predictors, split into a train and test set, which we'll consider a hold-out set and not train on, and remove all features with zero variance within a category (otherwise our logistic regression optimization will not converge with the default settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# separate out the target\n",
    "predictors = X.columns[X.columns != 'recs']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[predictors], X['recs'], test_size=0.25, random_state=12)\n",
    "\n",
    "# check for no variance within category of the target (problem for fitting regression)\n",
    "variance_per_category = X_train.groupby(y_train).var() == 0\n",
    "novariance = variance_per_category.sum() > 0\n",
    "X_train.drop(X_train.columns[novariance],\n",
    "             axis=1,\n",
    "             inplace=True)\n",
    "X_test.drop(X_test.columns[novariance],\n",
    "             axis=1,\n",
    "             inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.262225\n",
      "         Iterations 8\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                   recs   No. Observations:                78257\n",
      "Model:                        MNLogit   Df Residuals:                    78134\n",
      "Method:                           MLE   Df Model:                          120\n",
      "Date:                Wed, 13 Jun 2018   Pseudo R-squ.:                 0.07855\n",
      "Time:                        12:39:16   Log-Likelihood:                -98778.\n",
      "converged:                       True   LL-Null:                   -1.0720e+05\n",
      "                                        LLR p-value:                     0.000\n",
      "=======================================================================================================\n",
      "                             recs=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "editorsSelection__1                     0.4590      0.360      1.275      0.202      -0.247       1.165\n",
      "sectionName__Africa                     1.6307      0.512      3.185      0.001       0.627       2.634\n",
      "sectionName__Americas                   0.7283        nan        nan        nan         nan         nan\n",
      "sectionName__Art & Design               0.6067      0.314      1.934      0.053      -0.008       1.222\n",
      "sectionName__Asia Pacific               0.4094      0.142      2.886      0.004       0.131       0.687\n",
      "sectionName__Australia                  1.2325      1.324      0.931      0.352      -1.362       3.827\n",
      "sectionName__Baseball                   0.2160      0.349      0.619      0.536      -0.468       0.900\n",
      "sectionName__Book Review                0.0767      0.707      0.108      0.914      -1.309       1.463\n",
      "sectionName__Canada                     0.7673      0.602      1.275      0.202      -0.412       1.947\n",
      "sectionName__College Basketball         0.9303      0.682      1.363      0.173      -0.407       2.268\n",
      "sectionName__College Football           0.6050        nan        nan        nan         nan         nan\n",
      "sectionName__DealBook                   0.2229      0.196      1.137      0.256      -0.161       0.607\n",
      "sectionName__Eat                        0.4714      0.226      2.084      0.037       0.028       0.915\n",
      "sectionName__Economy                    0.6485      0.171      3.799      0.000       0.314       0.983\n",
      "sectionName__Editorials                 2.1920      1.036      2.116      0.034       0.162       4.222\n",
      "sectionName__Education Life             0.4711      0.562      0.838      0.402      -0.630       1.573\n",
      "sectionName__Energy & Environment       0.7138      0.364      1.962      0.050       0.001       1.427\n",
      "sectionName__Europe                     0.3071      0.088      3.478      0.001       0.134       0.480\n",
      "sectionName__Family                     0.5226      0.165      3.163      0.002       0.199       0.846\n",
      "sectionName__Golf                       0.0450      0.620      0.073      0.942      -1.170       1.260\n",
      "sectionName__Live                       0.6231      0.188      3.315      0.001       0.255       0.992\n",
      "sectionName__Media                      0.2750      0.134      2.055      0.040       0.013       0.537\n",
      "sectionName__Middle East                0.2989      0.094      3.177      0.001       0.114       0.483\n",
      "sectionName__Mind                       0.5813      0.408      1.426      0.154      -0.218       1.380\n",
      "sectionName__Move                       0.8776      0.207      4.243      0.000       0.472       1.283\n",
      "sectionName__Music                      0.2906      0.396      0.734      0.463      -0.485       1.066\n",
      "sectionName__Olympics                   0.2657      0.311      0.855      0.393      -0.344       0.875\n",
      "sectionName__Opinion | Politics         0.2193      0.454      0.483      0.629      -0.671       1.109\n",
      "sectionName__Personal Tech              0.6913      0.556      1.243      0.214      -0.399       1.781\n",
      "sectionName__Politics                   0.2314      0.051      4.550      0.000       0.132       0.331\n",
      "sectionName__Pro Basketball             0.1899      0.403      0.471      0.638      -0.600       0.980\n",
      "sectionName__Pro Football               0.2447      0.270      0.906      0.365      -0.285       0.774\n",
      "sectionName__Retirement                 1.4127      0.912      1.549      0.121      -0.375       3.200\n",
      "sectionName__Room For Debate            0.4391      0.877      0.501      0.617      -1.280       2.158\n",
      "sectionName__Rugby                      0.6096      1.232      0.495      0.621      -1.806       3.025\n",
      "sectionName__Soccer                     0.2818      0.491      0.574      0.566      -0.681       1.245\n",
      "sectionName__Student Loans             -0.0174      0.778     -0.022      0.982      -1.543       1.508\n",
      "sectionName__Sunday Review              0.1939      0.064      3.012      0.003       0.068       0.320\n",
      "sectionName__Television                 0.3045      0.150      2.030      0.042       0.010       0.599\n",
      "sectionName__Tennis                    -0.1627      0.679     -0.240      0.810      -1.493       1.167\n",
      "sectionName__Unknown                    0.0166      0.047      0.352      0.725      -0.076       0.109\n",
      "sectionName__Weddings                   0.6631      1.231      0.539      0.590      -1.749       3.075\n",
      "sectionName__Wine, Beer & Cocktails     0.0202      0.393      0.051      0.959      -0.749       0.790\n",
      "typeOfMaterial__Blog                   -0.1835   8.17e+13  -2.25e-15      1.000    -1.6e+14     1.6e+14\n",
      "typeOfMaterial__Brief                   1.0939      1.157      0.946      0.344      -1.173       3.361\n",
      "typeOfMaterial__Editorial              -0.0292      0.045     -0.647      0.518      -0.118       0.059\n",
      "typeOfMaterial__Letter                  0.4983      0.481      1.036      0.300      -0.445       1.441\n",
      "typeOfMaterial__News                   -0.3090      0.034     -9.095      0.000      -0.376      -0.242\n",
      "typeOfMaterial__News Analysis           0.0505      0.122      0.414      0.679      -0.188       0.289\n",
      "typeOfMaterial__Obituary (Obit)        -0.5922      0.541     -1.094      0.274      -1.653       0.469\n",
      "typeOfMaterial__Question               -1.3962      0.533     -2.619      0.009      -2.441      -0.351\n",
      "typeOfMaterial__Review                  0.0500      0.140      0.359      0.720      -0.223       0.324\n",
      "typeOfMaterial__briefing                0.2248      0.226      0.997      0.319      -0.217       0.667\n",
      "commentType__reporterReply              0.8113      1.274      0.637      0.524      -1.686       3.309\n",
      "documentType__blogpost                 -0.1839   5.92e+13  -3.11e-15      1.000   -1.16e+14    1.16e+14\n",
      "approveDate                          5.577e-09   5.98e-10      9.326      0.000    4.41e-09    6.75e-09\n",
      "articleWordCount                        0.0002   1.68e-05      9.954      0.000       0.000       0.000\n",
      "depth                                  -0.5778      0.022    -26.303      0.000      -0.621      -0.535\n",
      "printPage                               0.0044      0.001      3.101      0.002       0.002       0.007\n",
      "timespeople                             0.7181      0.038     18.741      0.000       0.643       0.793\n",
      "trusted                                 0.4775      0.080      5.936      0.000       0.320       0.635\n",
      "sharing                                 0.0077      0.041      0.187      0.852      -0.073       0.089\n",
      "const                                  -8.1782      0.555    -14.739      0.000      -9.266      -7.091\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "                             recs=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "editorsSelection__1                     1.5595      0.376      4.147      0.000       0.822       2.297\n",
      "sectionName__Africa                     1.0614      0.546      1.942      0.052      -0.010       2.132\n",
      "sectionName__Americas                   0.5032      0.230      2.192      0.028       0.053       0.953\n",
      "sectionName__Art & Design               1.1946      0.238      5.024      0.000       0.729       1.661\n",
      "sectionName__Asia Pacific               0.2248      0.110      2.040      0.041       0.009       0.441\n",
      "sectionName__Australia                  0.8207      0.587      1.399      0.162      -0.329       1.970\n",
      "sectionName__Baseball                  -0.4970      0.307     -1.618      0.106      -1.099       0.105\n",
      "sectionName__Book Review                0.2018      0.262      0.770      0.441      -0.312       0.715\n",
      "sectionName__Canada                     1.2000      0.548      2.191      0.028       0.127       2.273\n",
      "sectionName__College Basketball         1.0548      0.484      2.180      0.029       0.106       2.003\n",
      "sectionName__College Football           0.3777      1.023      0.369      0.712      -1.627       2.382\n",
      "sectionName__DealBook                   0.2841      0.207      1.373      0.170      -0.121       0.690\n",
      "sectionName__Eat                        0.2523      0.227      1.113      0.266      -0.192       0.697\n",
      "sectionName__Economy                    0.8745      0.161      5.421      0.000       0.558       1.191\n",
      "sectionName__Editorials                 2.1137      1.052      2.008      0.045       0.051       4.176\n",
      "sectionName__Education Life             0.9338      0.370      2.522      0.012       0.208       1.659\n",
      "sectionName__Energy & Environment       0.7747      0.367      2.110      0.035       0.055       1.494\n",
      "sectionName__Europe                     0.2667      0.089      2.981      0.003       0.091       0.442\n",
      "sectionName__Family                     1.0828      0.146      7.417      0.000       0.797       1.369\n",
      "sectionName__Golf                      -0.6318      0.677     -0.933      0.351      -1.958       0.695\n",
      "sectionName__Live                       1.0428      0.187      5.573      0.000       0.676       1.410\n",
      "sectionName__Media                      0.3601      0.132      2.735      0.006       0.102       0.618\n",
      "sectionName__Middle East                0.1879      0.095      1.971      0.049       0.001       0.375\n",
      "sectionName__Mind                       1.0187      0.361      2.823      0.005       0.311       1.726\n",
      "sectionName__Move                       0.7252      0.214      3.381      0.001       0.305       1.146\n",
      "sectionName__Music                      0.4654      0.377      1.234      0.217      -0.274       1.205\n",
      "sectionName__Olympics                   0.5526      0.291      1.900      0.057      -0.017       1.123\n",
      "sectionName__Opinion | Politics        -0.2083      0.494     -0.422      0.673      -1.177       0.760\n",
      "sectionName__Personal Tech              0.1868      0.596      0.314      0.754      -0.981       1.354\n",
      "sectionName__Politics                   0.2394      0.056      4.306      0.000       0.130       0.348\n",
      "sectionName__Pro Basketball            -0.5232      0.431     -1.213      0.225      -1.369       0.322\n",
      "sectionName__Pro Football               0.0168      0.266      0.063      0.950      -0.504       0.537\n",
      "sectionName__Retirement                 0.6648      0.878      0.757      0.449      -1.056       2.385\n",
      "sectionName__Room For Debate            0.9729      0.633      1.538      0.124      -0.267       2.213\n",
      "sectionName__Rugby                     -0.5317      1.444     -0.368      0.713      -3.362       2.299\n",
      "sectionName__Soccer                    -0.4320      0.444     -0.973      0.331      -1.302       0.438\n",
      "sectionName__Student Loans              1.1928      0.630      1.895      0.058      -0.041       2.427\n",
      "sectionName__Sunday Review              0.4235      0.061      6.950      0.000       0.304       0.543\n",
      "sectionName__Television                 0.5588      0.140      3.996      0.000       0.285       0.833\n",
      "sectionName__Tennis                    -0.1716      0.664     -0.258      0.796      -1.473       1.130\n",
      "sectionName__Unknown                    0.0425      0.044      0.971      0.331      -0.043       0.128\n",
      "sectionName__Weddings                  -0.2625      1.442     -0.182      0.856      -3.090       2.565\n",
      "sectionName__Wine, Beer & Cocktails    -0.6336      0.524     -1.209      0.227      -1.661       0.393\n",
      "typeOfMaterial__Blog                   -0.4626        nan        nan        nan         nan         nan\n",
      "typeOfMaterial__Brief                   1.5469      1.137      1.361      0.174      -0.681       3.775\n",
      "typeOfMaterial__Editorial              -0.1008      0.046     -2.191      0.028      -0.191      -0.011\n",
      "typeOfMaterial__Letter                  0.1456      0.520      0.280      0.780      -0.874       1.165\n",
      "typeOfMaterial__News                   -0.0216      0.031     -0.698      0.485      -0.082       0.039\n",
      "typeOfMaterial__News Analysis           0.2562      0.121      2.124      0.034       0.020       0.493\n",
      "typeOfMaterial__Obituary (Obit)         0.1082      0.257      0.421      0.674      -0.396       0.612\n",
      "typeOfMaterial__Question               -0.5693      0.449     -1.269      0.205      -1.449       0.310\n",
      "typeOfMaterial__Review                  0.1030      0.127      0.812      0.417      -0.146       0.352\n",
      "typeOfMaterial__briefing                0.5539      0.216      2.567      0.010       0.131       0.977\n",
      "commentType__reporterReply              1.6897      1.138      1.485      0.138      -0.540       3.920\n",
      "documentType__blogpost                 -0.4630        nan        nan        nan         nan         nan\n",
      "approveDate                          5.848e-09   4.34e-10     13.458      0.000       5e-09     6.7e-09\n",
      "articleWordCount                        0.0002   1.62e-05     12.517      0.000       0.000       0.000\n",
      "depth                                  -1.4998      0.027    -55.623      0.000      -1.553      -1.447\n",
      "printPage                               0.0058      0.001      4.688      0.000       0.003       0.008\n",
      "timespeople                             0.9266      0.058     15.885      0.000       0.812       1.041\n",
      "trusted                                 0.7595      0.078      9.758      0.000       0.607       0.912\n",
      "sharing                                -0.0066      0.040     -0.163      0.871      -0.086       0.072\n",
      "const                                  -7.6161      0.712    -10.701      0.000      -9.011      -6.221\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "                             recs=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "editorsSelection__1                     4.3892      0.352     12.477      0.000       3.700       5.079\n",
      "sectionName__Africa                     1.2080      0.599      2.018      0.044       0.035       2.381\n",
      "sectionName__Americas                   1.1088      0.216      5.129      0.000       0.685       1.532\n",
      "sectionName__Art & Design               1.1822      0.237      4.988      0.000       0.718       1.647\n",
      "sectionName__Asia Pacific               0.0983      0.115      0.852      0.394      -0.128       0.324\n",
      "sectionName__Australia                  1.4296        nan        nan        nan         nan         nan\n",
      "sectionName__Baseball                  -0.8515      0.336     -2.533      0.011      -1.510      -0.193\n",
      "sectionName__Book Review                0.3660      0.342      1.070      0.285      -0.305       1.037\n",
      "sectionName__Canada                     1.4226      0.540      2.635      0.008       0.365       2.481\n",
      "sectionName__College Basketball         0.9358      0.509      1.840      0.066      -0.061       1.933\n",
      "sectionName__College Football           1.1680      0.786      1.486      0.137      -0.372       2.708\n",
      "sectionName__DealBook                   0.3035      0.225      1.350      0.177      -0.137       0.744\n",
      "sectionName__Eat                        0.1998      0.253      0.790      0.430      -0.296       0.696\n",
      "sectionName__Economy                    0.9486      0.173      5.485      0.000       0.610       1.288\n",
      "sectionName__Editorials                 2.7252      1.040      2.620      0.009       0.686       4.764\n",
      "sectionName__Education Life             1.1243      0.394      2.853      0.004       0.352       1.897\n",
      "sectionName__Energy & Environment       0.1582      0.427      0.371      0.711      -0.679       0.995\n",
      "sectionName__Europe                     0.2344      0.092      2.534      0.011       0.053       0.416\n",
      "sectionName__Family                     1.6962      0.146     11.636      0.000       1.410       1.982\n",
      "sectionName__Golf                      -1.5318      0.837     -1.830      0.067      -3.173       0.109\n",
      "sectionName__Live                       1.2465      0.196      6.362      0.000       0.862       1.631\n",
      "sectionName__Media                      0.6442      0.129      5.006      0.000       0.392       0.896\n",
      "sectionName__Middle East               -0.0074      0.097     -0.076      0.939      -0.198       0.183\n",
      "sectionName__Mind                       1.1730      0.397      2.953      0.003       0.395       1.952\n",
      "sectionName__Move                       1.0937      0.218      5.007      0.000       0.666       1.522\n",
      "sectionName__Music                      1.4926      0.361      4.138      0.000       0.786       2.200\n",
      "sectionName__Olympics                   0.3839      0.317      1.212      0.226      -0.237       1.005\n",
      "sectionName__Opinion | Politics        -0.4520      0.540     -0.837      0.403      -1.510       0.607\n",
      "sectionName__Personal Tech              0.0901      0.649      0.139      0.890      -1.182       1.362\n",
      "sectionName__Politics                   0.3044      0.049      6.174      0.000       0.208       0.401\n",
      "sectionName__Pro Basketball            -0.4057      0.424     -0.958      0.338      -1.236       0.425\n",
      "sectionName__Pro Football              -0.0051      0.276     -0.019      0.985      -0.545       0.535\n",
      "sectionName__Retirement                 2.1258      0.795      2.675      0.007       0.568       3.683\n",
      "sectionName__Room For Debate            2.1098      0.497      4.246      0.000       1.136       3.084\n",
      "sectionName__Rugby                     -0.4761      1.465     -0.325      0.745      -3.346       2.394\n",
      "sectionName__Soccer                    -2.8093      1.056     -2.659      0.008      -4.880      -0.739\n",
      "sectionName__Student Loans              0.0017      0.912      0.002      0.999      -1.785       1.789\n",
      "sectionName__Sunday Review              0.7740      0.055     14.021      0.000       0.666       0.882\n",
      "sectionName__Television                 0.4282      0.148      2.901      0.004       0.139       0.718\n",
      "sectionName__Tennis                    -1.8809      1.177     -1.597      0.110      -4.189       0.427\n",
      "sectionName__Unknown                    0.1235      0.030      4.115      0.000       0.065       0.182\n",
      "sectionName__Weddings                   0.6322      1.303      0.485      0.628      -1.922       3.186\n",
      "sectionName__Wine, Beer & Cocktails    -1.7086      0.803     -2.128      0.033      -3.282      -0.135\n",
      "typeOfMaterial__Blog                   -0.6890        nan        nan        nan         nan         nan\n",
      "typeOfMaterial__Brief                   2.5995      1.113      2.335      0.020       0.417       4.782\n",
      "typeOfMaterial__Editorial              -0.2796      0.049     -5.673      0.000      -0.376      -0.183\n",
      "typeOfMaterial__Letter                  1.1771      0.482      2.443      0.015       0.233       2.122\n",
      "typeOfMaterial__News                    0.1103      0.032      3.410      0.001       0.047       0.174\n",
      "typeOfMaterial__News Analysis           0.3486      0.126      2.761      0.006       0.101       0.596\n",
      "typeOfMaterial__Obituary (Obit)         0.3944      0.262      1.505      0.132      -0.119       0.908\n",
      "typeOfMaterial__Question                0.0545      0.454      0.120      0.904      -0.835       0.944\n",
      "typeOfMaterial__Review                 -0.0446      0.136     -0.328      0.743      -0.311       0.222\n",
      "typeOfMaterial__briefing                0.1299      0.247      0.527      0.598      -0.353       0.613\n",
      "commentType__reporterReply              1.9714      1.268      1.554      0.120      -0.514       4.457\n",
      "documentType__blogpost                 -0.6890        nan        nan        nan         nan         nan\n",
      "approveDate                          5.796e-09   2.59e-10     22.364      0.000    5.29e-09     6.3e-09\n",
      "articleWordCount                        0.0002   1.69e-05     14.177      0.000       0.000       0.000\n",
      "depth                                  -2.7632      0.042    -65.326      0.000      -2.846      -2.680\n",
      "printPage                               0.0096      0.001      7.147      0.000       0.007       0.012\n",
      "timespeople                             0.9373      0.066     14.277      0.000       0.809       1.066\n",
      "trusted                                 1.7508      0.077     22.840      0.000       1.601       1.901\n",
      "sharing                                 0.0090      0.042      0.215      0.830      -0.073       0.091\n",
      "const                                  -6.4822      0.366    -17.714      0.000      -7.199      -5.765\n",
      "=======================================================================================================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.37      0.38      4713\n",
      "          1       0.35      0.15      0.21      6074\n",
      "          2       0.33      0.26      0.29      7681\n",
      "          3       0.40      0.68      0.50      7618\n",
      "\n",
      "avg / total       0.37      0.38      0.35     26086\n",
      "\n",
      "MLogit accuracy is about 0.38\n"
     ]
    }
   ],
   "source": [
    "# fit \n",
    "# This is equivalent to using SKlearn's MLogit with 'newton-cg' solver\n",
    "# LogisticRegression(multi_class='multinomial', solver='newton-cg'),\n",
    "X_logit = st.add_constant(X_train, prepend=False)\n",
    "MLogit = st.MNLogit(y_train, X_logit)\n",
    "logit_fit = MLogit.fit()\n",
    "# this is necessary for the summary:\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "print(logit_fit.summary())\n",
    "logit_y_hat = logit_fit.predict(exog=st.add_constant(X_test, prepend=False))\n",
    "# need to convert it to actual predictions as these are probabilities\n",
    "logit_y_hat = logit_y_hat.idxmax(axis=1)\n",
    "print(classification_report(y_test, logit_y_hat))\n",
    "print('MLogit accuracy is about %.2f' % accuracy_score(y_test, logit_y_hat))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, now we have our first (simple) fit and the first accuracy score - the model classified about 38% of cases correctly, which is an improvement of about 9% over the baseline (constant) model. The classification report shows that the model has the greatest amount of trouble guessing the second category (One or two upvotes), and is considerably better at guessing the fourth (most popular) category (recall column reports the share of cases of each category the classifier was able to correctly identify). Of all of the comments which received between one and two upvotes, our logistic regression classifier was able to recall only about 15%, in contrast to almost 70% for the fourth category (more than eight upvotes).\n",
    " \n",
    "Without delving too deeply in the interpretation of the coefficients, it seems like the numeric features generally had the greatest impact. We'll say more about them in the next section, but these are features such as the length of the original article, the **depth** of the comment, whether the comment was recommended by the NYTimes staff (**editorSelection**), posted by NYTimes staff members or trusted users. While the various categories derived from the **sectionName** variable generally weren't that important, there were a few very popular categories there - for example 'Family' and 'Sunday Review.' Of course, all of the coefficients here are to be interpreted relative to the omitted reference category, but our focus here is on prediction so we won't dwell on the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A bag of classifiers <a name='classifiers'></a>\n",
    "\n",
    "Next, let's create a bag of classifiers. We are somewhat agnostic as to the most appropriate one at this stage, so we'll include several. In addition to logistic regression, we'll do Ridge regression (essentially a penalized regression), nearest neighbors and two ensemble models (Random Forest and Extreme Gradient Boost). Feel free to drop in your favorite classifier in the mix. I like XGB both for speed (run on a GPU it is quite fast), which allows more experiments, and for the fact that it can report feature importance - which features were present in more trees and how much gain in coverage did each provide. We won't do much model tuning at this stage, relying on the rather conservative default parameter values baked into Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "models = [('MLogit', LogisticRegression(n_jobs=-1)),\n",
    "          ('Ridge', RidgeClassifier()),\n",
    "          ('KNN', KNeighborsClassifier(n_jobs=-1)),\n",
    "          ('RandomForest', RandomForestClassifier(n_jobs=-1)),\n",
    "          ('XGB', XGBClassifier(tree_method='gpu_hist',\n",
    "                                n_estimators=50)),\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And let's put together a pipeline to report the scores on each of our these classifiers. It will allow us to compare classification performance after the feature engineering stage. To be on the safe side, we rescale the data with scikit-learn's standard scaler (center at zero and divide by standard deviation), although given the classifier families we chose this is not strictly necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fitting MLogit\n",
      "Accuracy of MLogit: 0.3769\n",
      "\n",
      "Classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       None       0.39      0.38      0.39      4713\n",
      "     1 or 2       0.35      0.14      0.20      6074\n",
      "     3 to 8       0.33      0.23      0.27      7681\n",
      "  9 or more       0.40      0.71      0.51      7618\n",
      "\n",
      "avg / total       0.37      0.38      0.34     26086\n",
      "\n",
      "ROC_AUC_score: 0.5577\n",
      "\n",
      "\n",
      "Fitting Ridge\n",
      "Accuracy of Ridge: 0.3728\n",
      "\n",
      "Classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       None       0.38      0.41      0.39      4713\n",
      "     1 or 2       0.35      0.10      0.16      6074\n",
      "     3 to 8       0.33      0.21      0.25      7681\n",
      "  9 or more       0.39      0.73      0.51      7618\n",
      "\n",
      "avg / total       0.36      0.37      0.33     26086\n",
      "\n",
      "ROC_AUC_score: 0.5563\n",
      "\n",
      "\n",
      "Fitting KNN\n"
     ]
    }
   ],
   "source": [
    "def predict_recs(X_train=X_train, \n",
    "                 y_train=y_train,\n",
    "                 X_test=X_test,\n",
    "                 y_test=y_test,\n",
    "                 models=models,\n",
    "          target_names=['None', '1 or 2', '3 to 8', '9 or more']):\n",
    "    '''Fits and scores models'''\n",
    "    Accuracy = {}\n",
    "    for name, model in models:\n",
    "        pipe = make_pipeline(scaler_standard, model)\n",
    "        print()\n",
    "        print('\\nFitting ' + name)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_hat = pipe.predict(X_test)\n",
    "        Accuracy[name] = np.round(accuracy_score(\n",
    "            y_test, y_hat), 4)\n",
    "        print('Accuracy of %s: %.4f' % (name, Accuracy[name]))\n",
    "        print('\\nClassification report:\\n')\n",
    "        print(classification_report(\n",
    "            y_test, y_hat, target_names=target_names))\n",
    "        y_hat_bin = label_binarize(y_hat, range(3))\n",
    "        y_true_bin = label_binarize(y_test, range(3))\n",
    "        ROC_AUC_score = roc_auc_score(y_true_bin, y_hat_bin)\n",
    "        print('ROC_AUC_score: %.4f' % ROC_AUC_score)\n",
    "        # print(confusion_matrix(\n",
    "        #     y_test, y_hat))\n",
    "    return Accuracy\n",
    "\n",
    "\n",
    "# predict with only existing features\n",
    "minimal_features = predict_recs(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some of our models did a little better than others, notably Random Forest seems to give the best predictions, at least at this stage. All of them had trouble with the second category, perhaps because it is difficult in principle to identify comments which received one-to-two upvotes as opposed to zero or more than two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "feature Engineering <a name='featureengineering'></a>\n",
    "\n",
    "Time to create some meaningful features! We'll start with the numeric features that are already in the dataset and which showed much promise in the simple logistic model.\n",
    "\n",
    "We wil create features only on the dev set for now, which would take quite a bit less time. Eventually we would like to utilize the full data that we have. In order to speed things up a bit, let's use some multiprocessing (ie all of the cores we have available). I wrote a little function wrapper that spreads the task over as many cores as the system makes available and displays a nice progress bar so we know how long it will take. The overhead involved with multiprocessing usually makes it less time efficient to bother, but with a dataset of 2 million rows, it will tend to be faster. (We won't run it )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count, Pool\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def multip(func, iterable):\n",
    "    '''Simple wrapper for multiprocessing a function over an iterable. Preserves order.'''\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        out = list(tqdm_notebook(pool.imap(func, iterable),\n",
    "                        total=len(iterable),\n",
    "                        mininterval=1))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Features based on the original variables <a name='originalvars'></a>\n",
    "\n",
    "The original numeric features in the data contain information on some potentially important attributes of both comments and articles. We care about the article features simply because some articles are much more likely to garner more attention. Consequently, the comments on these articles will tend to get more upvotes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "reply <a name='originalvars'></a>\n",
    "\n",
    "**inReplyTo** - an original variable which simply tells us which comment the current comment is responding to (based on the ID of the comment) or holds a value of zero if it is not a response.\n",
    "One way to extract a useful feature from this would be to create a variable which takes a value of the number of recommendations/upvotes which the original comments obtained and a value of zero if this is not a reply at all. The expectation is responding to a popular comment should get you more visibility and, by extention, more upvotes. We can think of this as the Reddit top-comment hijacking strategy, which will be familiar to anyone who has used Reddit, though the visibility of the responses is nowhere near as prominent as it is on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# feature is zero if not a reply and number of upvotes of original comment if it is a reply\n",
    "def replycounter(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x != 0:\n",
    "        return df.recommendations.at[int(np.where(df.commentID == x)[0])]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# run only on the dev set for speed\n",
    "X['reply'] = multip(replycounter, df.inReplyTo[dev_set_index])\n",
    "\n",
    "# uncomment this for full set\n",
    "# X_full['reply'] = multip(replycounter, df.inReplyTo)\n",
    "\n",
    "print(X.reply.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Another 'object'-type variable which we could utilize is **byline**, which reports the authors of an article. <a name='byline'></a>\n",
    "Here's a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.byline.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Unsurprisingly, some authors tend to generate many more comments than others (the top being the Editorial Board of course, followed by many of the op-ed contributors). One quick and easy way to make use of this is to simply get dummies for each of the top authors, in our case we can do it for the top 20, although obviously one could go for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# encode all categories of byline\n",
    "OneH df.byline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Next, I noticed in the MLogit output that one of the time variables seemed to have a large impact - **approveDate**. This variable effectively report the exact timing of a comment being approved, and therefore appearing online - kind of like the publication time of a comment. Let's take a peek at what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.approveDate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ooh, that's ugly - and meaningless at first glance. After some digging around we figure out that this variable is in Posix format: it reports seconds since 1970-01-01. Let's create a few features that can be meangingful for us: \n",
    "\n",
    "1. **approveHour** - Hour of the day in which a comment was published. We expect, for example, that people are reading and responding to online content more during the day than at night. Categorical.\n",
    "\n",
    "2. **approveDay**  - Same for day of the week, perhaps weekends are more procrastination-prone than weekdays. Categorical.\n",
    "\n",
    "2. **hoursAfterArticle** - The number of hours elapsed between an article's publication and the corresponding comments' approval (and therefore publication). We can use the **pubDate** original variable from the articles dataset for the former. That one is coded as a string, so we'll have to convert it to a time format as well. We expect that if too much time passes after an article is published, it will simply get too few eyeballs. Continuous.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# fix article publication date\n",
    "print(df.pubDate.head())\n",
    "df.pubDate = pd.to_datetime(df.pubDate)\n",
    "print(df.pubDate.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# convert all time columns from posix to regular format (we'll only use one of them)\n",
    "print(df.approveDate.head())\n",
    "timecolumns = ['approveDate', 'createDate', 'updateDate']\n",
    "df[['approveTime', 'createTime', 'updateTime']] = df[timecolumns].apply(\n",
    "    lambda t: pd.to_datetime(t, unit='s'))\n",
    "print(df.approveTime.head())\n",
    "print(df.approveTime.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# change the index to approveTime\n",
    "df.index = df.approveTime\n",
    "# sample by hour, (to the next hour)\n",
    "df['approveHour'] = [\n",
    "    str(x) + 'AM' if x < 12 else str(x - 12) + 'PM' for x in df.index.hour]\n",
    "# sample by day\n",
    "df['approveDay'] = df.index.weekday_name\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.approveHour.head())\n",
    "# add dummies for both to df using the function we built earlier\n",
    "df_temp = OneHotEncoding(['approveHour',\n",
    "                          'approveDay'], data=df)\n",
    "# combine the two types of features and remove the old one\n",
    "X_full = pd.concat([X_full, df_temp], axis=1)\n",
    "del X_full['approveDate']\n",
    "# and place them in the dev set as well\n",
    "X = pd.concat([X, df_temp.loc[dev_set_index, :]], axis=1)\n",
    "print(X.shape)\n",
    "del df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# create a feature for time of posting of comment since article published\n",
    "df['timeDelta'] = df.approveTime - df.pubDate\n",
    "# convert this timedelta object to hours (downsample)\n",
    "df['hoursAfterArticle'] = df.timeDelta.astype(\n",
    "    'timedelta64[h]')\n",
    "\n",
    "print(df.hoursAfterArticle.head())\n",
    "print(df.hoursAfterArticle.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ooops! Negative hours... Hmm, the minimum value of the new variable is -8. Since we haven't yet discovered time travel, this means that either we are experiencing issues with time zones or there's simply some errors in the data - some articles appeared before their publication time or some comments' approval time was misrecorded. Either way, the issue affects very few cases, so we'll simply set all of the negative values to zero, noting the fact that we may be introducing some noise and even bias here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(df[df.hoursAfterArticle < 0].shape[0])\n",
    "df.loc[df.hoursAfterArticle < 0, 'hoursAfterArticle'] = 0\n",
    "# And assign to the large DataFrame:\n",
    "X_full['hoursAfterArticle'] = df['hoursAfterArticle']\n",
    "# and the small dev set\n",
    "X['hoursAfterArticle'] = X_full.loc[dev_set_index, 'hoursAfterArticle']\n",
    "print(X.hoursAfterArticle.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Features based on raw text data  <a name='textdata'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, here comes the messy raw text manipulation. We have so far not utilized the actual body of comments as well as some of the raw text data we possess about the articles. So let's do that.\n",
    "My intuition about comment upvotes is that generally comments will be more popular when they read like their author put in time and effort to write them, made them more informative, polished and balanced. This could mean quite a few different things, but here's one way to approach the quantification problem. We expect that popular comments will not be too short (low effort!), will use more sophisticated language (ie more rare words, longer words, longer sentences, etc.), will have no or few spelling mistakes (no excuses now that most browsers offer spellcheck out of the box), and will not be too negative-sounding (positive or neutral sentiment). These are of course little more than hunches at this stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A NYTimes vocabulary <a name='vocab'></a>\n",
    "\n",
    "To get measures of all of these, we'll use a few external libraries and one more dataset. I would like to measure the extent to which comments use _the language of the NYTimes_. To that effect, it makes sense to create a vocabulary based on the text of NYTimes articles. I found another wonderful dataset on Kaggle - available \n",
    "[here](https://www.kaggle.com/nzalake52/new-york-times-articles/data). It contains over 8,000 articles, and while not very well documented, should more than suffice for our purposes here.\n",
    "\n",
    "For both speed and ease of use, we can use the built-in tokenizer in Scikit-learn, tuning it a bit in order to get only words. We tokenize the raw text files of the articles' bodies immediately upon reading them, append them to a list and transform it into a Pandas Series (for convenience). Then, we fit the tokenizer to them to learn the frequency of each word's usage. Frequency is important here, as we want to get a sense whether a comment uses rare english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Get some NYTimes articles to train on\n",
    "counter = CountVectorizer(stop_words='english',\n",
    "                          strip_accents='unicode',\n",
    "                          analyzer='word',\n",
    "                          min_df=1)\n",
    "# first get the tokenizer tool from CountVectorizer\n",
    "tokenize = counter.build_analyzer()\n",
    "docs = []\n",
    "doc = ''\n",
    "\n",
    "with open('./Data/nytimes_news_articles.txt', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('URL'):\n",
    "            if doc != '':\n",
    "                docs.append(' '.join(tokenize(doc)))\n",
    "            doc = ''\n",
    "        else:\n",
    "            doc += line\n",
    "\n",
    "docs = pd.Series(docs)\n",
    "print(docs.sample())\n",
    "# fit the CountVectorizer to the data\n",
    "counter.fit(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Whenever we tokenize it is a good idea to take a look at the beginning and end of the token lists, remembering that raw text is messy business. A useful little built-in function allows us to explore the dictionary we are building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "token_names = counter.get_feature_names()\n",
    "# last 10 tokens\n",
    "print(token_names[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Uh-oh! This doesn't look like english!\n",
    "After some digging around, the culprit is several articles in Asian characters. \n",
    "Let's identify and remove all of the articles in which a large portion of the words are not in English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def score_English(article):\n",
    "    '''Report the percent of words in a document which are not English (ASCI)'''\n",
    "    if not article:\n",
    "        return np.nan\n",
    "    else:\n",
    "        n_english = 0\n",
    "        for token in article:\n",
    "            try:\n",
    "                token.encode('ascii')\n",
    "            except UnicodeEncodeError:\n",
    "                continue\n",
    "            else:\n",
    "                n_english += 1\n",
    "        return np.round(n_english / len(article) * 100, 2)\n",
    "\n",
    "\n",
    "percent_english = docs.apply(score_English)\n",
    "print(percent_english.sort_values().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We remove the non-English articles and refit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# remove them:\n",
    "docs = docs[percent_english > 20]\n",
    "# and try again:\n",
    "counter.fit(docs)\n",
    "# get the token names again\n",
    "feature_names = counter.get_feature_names()\n",
    "# the end looks good now:\n",
    "print(feature_names[-30:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And the beginning of the list is full of numbers, let's get rid of those as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(feature_names[:10])\n",
    "vocab = feature_names[2330:]\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Obviously we are not quite done yet - the tokenizer picked up quite a few non-words, let's run each by a proper English dictionary and eliminate the non-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "us_english = enchant.Dict(\"en_US\")\n",
    "# create a clean copy of the dictionary only with recognized English words\n",
    "\n",
    "vocab = [word for word in vocab if us_english.check(word)]\n",
    "print(vocab[:10], vocab[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, this looks much better, we have a proper english vocabulary based on the NYTimes. This is why did all of the work: using an IDF counter we can get the frequency of each recognized word and use that to build several features based on the diversity of a comment's vocabulary.\n",
    "\n",
    "All of this will be built on a measure commonly used in document classification in Natural Language Processing tasks called 'IDF' or 'inverse document frequency.' It measures how infrequently a word is used in a body of documents (how rare the word is), which is quite usefull for the typical document classification task, usually normalized by multiplying by term frequency, get 'TFIDF.' This is not what we need here though - we simply want IDF, so here's what it looks like and how to get it.\n",
    "First, we train a a tokenizer to the docs using only our cleaned up vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(norm=None,\n",
    "                        vocabulary=vocab,\n",
    "                        min_df=1,\n",
    "                        )\n",
    "\n",
    "tfidf.fit(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now, let's see if it is behaving as expected. Here's a very simple example that shows us the IDF value for a word that appears in a given percentage of documents, using the conventional formula for IDF ([wiki](https://en.wikipedia.org/wiki/Tf-idf)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# check an individual word's idf:\n",
    "num_docs = 10000\n",
    "doc_freq = [1, 5, 10, 50, 100, 500, 1000, 5000, 10000]\n",
    "idf = [np.log((1 + num_docs)/(1 + x)) + 1 for x in doc_freq]\n",
    "for x, y in zip(doc_freq, idf):\n",
    "    print('\\nA term which appears in %.2f%% of documents has an IDF of %.2f.' %\n",
    "          (x/num_docs*100, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, now let's see run some English words, in decreasing order of frequency, by our trained vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def word_idf(word, tfidf=tfidf):\n",
    "    idf = np.round(tfidf.idf_[tfidf.vocabulary_[word]], 2)\n",
    "    print('\\n\\'' + word + '\\' has an IDF of %.2f.' % idf)\n",
    "\n",
    "\n",
    "word_idf('zealot')\n",
    "word_idf('edifice')\n",
    "word_idf('prolific')\n",
    "word_idf('simple')\n",
    "word_idf('good')\n",
    "word_idf('like')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "That will do. \n",
    "Let's get back to the feature engineering. <a name='dataloading'></a> \n",
    "Using our trained IDF counter, we can transform all comments into a matrix of IDF scores (each row is an array of the IDF scores of the the tokens present in a comment). Then we can use that matrix (and some additional wizardry) to create a bincount - a count of each IDF integer. Think about this as the vocabulary rarity profile of a comment. While we could just rely on the mean IDF (or one of the other basic stats), doing a bincount allows us to probe a little deeper - two comments might have a very different IDF profile yet have the same mean IDF.\n",
    "For additional convenience, we create a simple summarizer function which reports a count, minimum, mean, standard deviation and maximum value given an array. In case a comment contains no recognizable words, we simply assign a value of zero to all measurables. A safer choice here would be to exclude the comment altogether - but very few comments fall in this category so are are not worried about bias too much (especially given the size of the full dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# grab only the dev set comments:\n",
    "comments = df.commentBody[dev_set_index]\n",
    "# uncomment next line for full set:\n",
    "# comments = df.commentBody\n",
    "\n",
    "def summarizer(array):\n",
    "    '''Simple summary from an array: count, min, mean, stand dev, max'''\n",
    "    return np.array([array.size,\n",
    "                     np.min(array),\n",
    "                     np.mean(array),\n",
    "                     np.std(array),\n",
    "                     np.max(array)])\n",
    "\n",
    "\n",
    "def comment_idf_profile(row):\n",
    "    '''Summarize idf scores for each recognized token in a comment and provide a bincount percent of idf scores.'''\n",
    "    tokens = comment_tf[row, :].data\n",
    "    if tokens.size != 0:\n",
    "        idfs = comment_matrix[row, :].data / tokens\n",
    "        out_summary = summarizer(idfs)\n",
    "        out_bin = np.bincount(idfs.astype(int), minlength=10)[1:]\n",
    "        out_bin_percent = out_bin / len(tokens)\n",
    "        output = np.hstack([out_summary, out_bin_percent])\n",
    "    else:\n",
    "        output = np.zeros(14)\n",
    "    return output\n",
    "\n",
    "comment_matrix = tfidf.transform(comments)\n",
    "comment_matrix.sort_indices()  # it's inplace\n",
    "counter = CountVectorizer(vocabulary=vocab,\n",
    "                          min_df=1)\n",
    "comment_tf = counter.transform(comments)\n",
    "# comment_tokens = list(map(tokenize, comments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scored_df = multip(comment_idf_profile, range(comment_matrix.shape[0]))\n",
    "scored_df = pd.DataFrame(scored_df)\n",
    "idf_labs_percent = ['Idf' + str(x) + 'Percent' for x in range(1, 10)]\n",
    "scored_df.columns = ['recognizedWordCount',\n",
    "                     'MinIdf',\n",
    "                     'MeanIdf',\n",
    "                     'StdDevIdf',\n",
    "                     'MaxIdf'] + idf_labs_percent\n",
    "# quick sanity check\n",
    "print(scored_df.info())\n",
    "print(scored_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "All in all, we ended up creating 14 new features, we won't worry about the correlations between them just yet, but we'll take a look at those before prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Time to throw in the kitchen sink! <a name='kitchensink'></a>\n",
    "\n",
    "Let's create more features based on more of the indicators we are looking for. Relying on two NLP libraries (TextBlob and the conventional NLTK), we obtain a host of features: basic stats on words and word length, basic stats on sentences and sentence length, sentiment polarity (positive-negative) and subjectivity (subjective-objective) scores, spelling (percent of correctly spelled words), and even part-of-speech breakdown (how many nouns, adjectives, adverbs and so on as a percentage of all words.) The full list of parts-of-speech tags is available \n",
    "[here](httss://www.clips.uantwerpen.be/pages/mbsp-tags).\n",
    "\n",
    "For most of these features, our expectation is that generally comments should fall in an ideal range - not too short, nor too long in terms of sentence length and comment length; not too many adjectives but also not too few and so on. Of course, in terms of spelling we expect lower error rate to be better.\n",
    "\n",
    "A few additional small considerations. We put all of these indicators in one large function simply to economize on the overhead associated with multiprocessing. Also, there is a little regular expression magic at the beginning of the function to fix a very common error - no space after end of sentence punctuation (.?!). We fix that because it leads to more noise in all of our features. We spell-check all words which are not 'proper nouns', meaning names, as that should generate more accurate counts. Finally, comments shorter that three characters are coded as all zeros - they are simply too short to get much information. Again, one could also eliminate them out of the sample if worried about bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get all the POS tags to create an array\n",
    "from nltk.data import load\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from enchant.checker import SpellChecker\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "spell_checker = SpellChecker(us_english)\n",
    "universal_tags = load('help/tagsets/upenn_tagset.pickle')\n",
    "tags = universal_tags.keys()\n",
    "tag_labels_percent = [label + '_Percent' for label in tags]\n",
    "\n",
    "\n",
    "def comment_stats(comment):\n",
    "    '''Report stats for a comment. Stats on sentences, words, part-of-speech tags as portion of the total, spelling and sentiment scores. Comments shorter than 3 characters output zeroes.'''\n",
    "    if len(comment) < 3:\n",
    "        return np.zeros(58)\n",
    "    ################################################################################\n",
    "    # insert space after period or comma if there isn't one already (common error)\n",
    "    comment = re.sub(r'(?<=[.,?!])(?=[^\\s])', r' ', comment)\n",
    "    ################################################################################\n",
    "    # sentence stats\n",
    "    blob = TextBlob(comment)\n",
    "    sentences = blob.sentences\n",
    "    tokenized_sents = [sentence.words for sentence in sentences]\n",
    "    sent_lengths = np.array([len(sentence)\n",
    "                             for sentence in tokenized_sents])\n",
    "    out_sent = summarizer(sent_lengths)\n",
    "    ################################################################################\n",
    "    # word stats\n",
    "    word_lengths = np.array([len(word) for word in blob.words])\n",
    "    if word_lengths.size == 0:\n",
    "        return np.zeros(58)\n",
    "    out_word = summarizer(word_lengths)\n",
    "    ################################################################################\n",
    "    # sentiment analysis: polarity and objectivity\n",
    "    out_polarity = list(blob.sentiment)\n",
    "    ################################################################################\n",
    "    # spellcheck stats\n",
    "    # replace most punctuation by space for whitespacetokenizer, leave apostrophes for contractions\n",
    "    comment_nopunct = re.sub(r'[,.?!#():-=\"“”%$]', ' ', comment)\n",
    "    blob_nopunct = TextBlob(comment_nopunct, tokenizer=WhitespaceTokenizer())\n",
    "    non_NNP = [word for word, tag in blob_nopunct.tags if tag !=\n",
    "               'NNP']\n",
    "    if not non_NNP:\n",
    "        out_spell = np.zeros(1)\n",
    "    else:\n",
    "        spell_errors = 0\n",
    "        for word in non_NNP:\n",
    "            try:\n",
    "                spell_errors += not spell_checker.check(word.strip('\\'\\`'))\n",
    "            except:\n",
    "                spell_errors += 1\n",
    "        out_spell = np.array(spell_errors / len(non_NNP))\n",
    "    ################################################################################\n",
    "    # part of speech stats\n",
    "    fd = FreqDist(tag for (word, tag) in blob.tags)\n",
    "    ordered_freqs = np.array(\n",
    "        [fd[key] if key in fd.keys() else 0 for key in tags])\n",
    "    out_pos_percent = np.squeeze(ordered_freqs / len(word_lengths))\n",
    "    ################################################################################\n",
    "    return np.hstack([out_word, out_sent, out_polarity, out_spell,\n",
    "                      out_pos_percent])\n",
    "\n",
    "\n",
    "comment_stats_df = multip(comment_stats, comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "comment_stats_df = pd.DataFrame(comment_stats_df)\n",
    "comment_stats_df.columns = ['WordCount',\n",
    "                            'minWordLength',\n",
    "                            'meanWordLength',\n",
    "                            'stdDevWordLength',\n",
    "                            'maxWordLength',\n",
    "                            'SentCount',\n",
    "                            'minSentLength',\n",
    "                            'meanSentLength',\n",
    "                            'stdDevSentLength',\n",
    "                            'maxSentLength',\n",
    "                            'commentPolarity',\n",
    "                            'commentObjectivity',\n",
    "                            'commentSpellErrorsPercent'] + tag_labels_percent\n",
    "# quick sanity check\n",
    "comment_stats_df.describe()\n",
    "comment_stats_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# add the both sets of new features to the dev set\n",
    "X = pd.concat([X.reset_index(drop=True),\n",
    "               scored_df,\n",
    "               comment_stats_df], axis=1)\n",
    "\n",
    "# uncomment for full set\n",
    "# X_full = pd.concat([X_full,\n",
    "#                scored_df,\n",
    "#                comment_stats_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, before we continue with the feature engineering, let's do a small unit test: let's look at the body of a comment and see if the features we just created match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(comments.iloc[88888])\n",
    "print()\n",
    "print(X.iloc[88888, 83:143])\n",
    "print(X.iloc[88888, 143:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Great, it's a match: number of words, sentences, spelling, etc.\n",
    "Final step in the feature engineering: Token features <a name='articletextdata'></a>\n",
    "Basically, these are simply binary features of whether a certain token (usually word) is included or not. To economize on time and memory, we'll limit ourselves to the top (most frequent) 50 tokens. Obviously, we could easily increase the count or eliminate the limitation altogether, but we would end up with many more features.\n",
    "The first one will be based on the list of keywords that came with each article, **keywords**. Quite simply, our expectation here is that some keywords describing articles may be associated with more comments and upvotes in general (hot topics).\n",
    "This is what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.keywords.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We simply tokenize the keyword lists, this time tuning the tokenizer to remove the artefacts of the lists and split on commas. Essentially, we are building a word list of the most commonly occuring keywords and record whether an article (and therefore all the comments attached to it) contains them in the description or not. We fit (train) on the full set but transform (count) only the dev set. The result is a sparse matrix, which we will convert to dense before the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "keywords = df.keywords.iloc[dev_set_index]\n",
    "\n",
    "# # uncomment for full set\n",
    "# keywords = df.keywords\n",
    "\n",
    "def keyword_tokenizer(keyword):\n",
    "    '''Split into keywords (phrases and remove all quotes and brackets)'''\n",
    "    return [phrase.strip('\\'\\[\\] ') for phrase in keyword.split('\\',')]\n",
    "\n",
    "\n",
    "counter_keywords = CountVectorizer(stop_words='english',\n",
    "                                   analyzer='word',\n",
    "                                   tokenizer=keyword_tokenizer,\n",
    "                                   max_features=50)\n",
    "counter_keywords.fit(df.keywords)\n",
    "common_keywords = counter_keywords.transform(keywords)\n",
    "keyword_features = counter_keywords.get_feature_names()\n",
    "keyword_features = ['Keyword:\"' + feature +\n",
    "                    '\"' for feature in keyword_features]\n",
    "print(keyword_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Yep, this does seem like a list of hot topics in the news for the two periods the articles covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally, the last feature to be engineered is the same counter for most commonly occuring words, but this time applied to the comments themselves. We'll be a little more generous and allow the top 100 such tokens to be counted (and again you could easily increase the number of tokens here). We will also exclude extremely common tokens - ones that appear in more than 30% of the comments and look for either single tokens or bigrams of tokens. Warning: this will take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# exclude very common words (appear in more than half the comments)\n",
    "counter = CountVectorizer(stop_words='english',\n",
    "                          analyzer='word',\n",
    "                          ngram_range=(1, 2),\n",
    "                          max_df=.3,\n",
    "                          max_features=100,\n",
    "                          )\n",
    "\n",
    "counter.fit(df.commentBody)\n",
    "common_tokens = counter.transform(comments)\n",
    "token_names = counter.get_feature_names()\n",
    "token_names = ['CommentWord:\"' + feature + '\"' for feature in token_names]\n",
    "print(token_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add them to the dev set. We also downgrade a few of the data types to save on memory (this is not strictly necessary, but it is useful with the full set which easily runs over memory limits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X,\n",
    "               pd.DataFrame(common_keywords.toarray(),\n",
    "                            columns=keyword_features),\n",
    "               pd.DataFrame(common_tokens.toarray(),\n",
    "                            columns=token_names)],\n",
    "              axis=1)\n",
    "\n",
    "# # uncomment for full set\n",
    "# X_full = pd.concat([X_full.reset_index(drop=True),\n",
    "#                     pd.DataFrame(common_keywords.toarray(),\n",
    "#                                  columns=keyword_features),\n",
    "#                     pd.DataFrame(comment_tokens.toarray(),\n",
    "#                                  columns=token_names)],\n",
    "#                    axis=1)\n",
    "\n",
    "# Memory saving type conversion\n",
    "# this is dangerous when storing very large numbers to store, but we don't have those here\n",
    "print(X.info())\n",
    "# ints\n",
    "for column in X.columns[X.dtypes.eq('int')]:\n",
    "    X[column] = X[column].astype('int8')\n",
    "# floats \n",
    "for column in X.columns[X.dtypes.eq('float')]:\n",
    "    X[column] = X[column].astype('float32')\n",
    "print(X.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "top_correlations(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "OK, one major issue here. It seems our two number-of-word counters basically report the same measure, even though they use different tokenizers. We remove WordCount and take a quick look at the correlations with the target, just to get an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X.drop('WordCount', inplace=True, axis=1)\n",
    "\n",
    "# # uncomment for full set\n",
    "# X_full.drop('WordCount', inplace=True, axis=1)\n",
    "\n",
    "correlations = X.corrwith(X.recs)\n",
    "correlations.reindex(correlations.abs().sort_values(\n",
    "    ascending=False).index).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Training & Re-evaluation <a name='training'></a>\n",
    "At last, time to see whether the feature engineering paid off. \n",
    "As usual, we split the dev set into training and test and remove zero-variance features within a category of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# separate out the target\n",
    "predictors = X.columns[X.columns != 'recs']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[predictors], X['recs'], test_size=0.25, random_state=12)\n",
    "\n",
    "# check for no variance within category of the target (problem for fitting regression)\n",
    "variance_per_category = X_train.groupby(y_train).var() == 0\n",
    "novariance = variance_per_category.sum() > 0\n",
    "X_train.drop(X_train.columns[novariance],\n",
    "             axis=1,\n",
    "             inplace=True)\n",
    "X_test.drop(X_test.columns[novariance],\n",
    "             axis=1,\n",
    "             inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And fit the logistic regression classifier again: <a name='finallogit'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# MLogit fit\n",
    "X_logit = st.add_constant(X_train, prepend=False)\n",
    "MLogit = st.MNLogit(y_train, X_logit)\n",
    "logit_fit = MLogit.fit()\n",
    "# print(logit_fit.summary())\n",
    "logit_y_hat = logit_fit.predict(exog=st.add_constant(X_test, prepend=False))\n",
    "# need to convert it to actual predictions as these are probabilities\n",
    "logit_y_hat = logit_y_hat.idxmax(axis=1)\n",
    "print()\n",
    "print(classification_report(y_test, logit_y_hat))\n",
    "print('MLogit accuracy is about %.2f' % accuracy_score(y_test, logit_y_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Yay! Accuracy went up by four percent relative to the minimal feature set. And the classifier correctly recalls the second class 20% of the time, a 5% improvement. Uncomment the summary command to see the significance of individual features (long output...).\n",
    "\n",
    "Next, let's use our bag of classifiers: <a name='finalclassifiers'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "predict_recs(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So increasing the number of predictors posed a problem for some of our classifiers, let's increase their capacity to handle more features by upgrading the key parameter value for each one that can be tuned quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "models = [('MLogit', LogisticRegression(n_jobs=-1)),\n",
    "          ('Ridge', RidgeClassifier()),\n",
    "          ('KNN', KNeighborsClassifier(n_neighbors=200, n_jobs=-1)),\n",
    "          ('RandomForest', RandomForestClassifier(n_estimators=200, n_jobs=-1)),\n",
    "          ('XGB', XGBClassifier(tree_method='gpu_hist',\n",
    "                                n_estimators=200)),\n",
    "          ]\n",
    "all_features = predict_recs(X_train, y_train, X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since some classifiers tend to do better with a reduced number of dimensions, let's try that using Principal Component Analysis. Obviously we could gridsearch the optimal number of components to reduce down to, but let's take a quick look at what happens to our predictive accuracy with 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dim_reduce = PCA(n_components=50)\n",
    "X_train_reduced = dim_reduce.fit_transform(X_train)\n",
    "X_test_reduced = dim_reduce.transform(X_test)\n",
    "print(X_train_reduced.shape)\n",
    "print(X_test_reduced.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "reduced_features = predict_recs(X_train_reduced, y_train, X_test_reduced, y_test, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's fine-tune the Extreme Gradient Boost a little bit - there is a way to find the optimal number of trees (estimators) by iteratively adding and comparing accuracy on an evaluation set. We'll allow the number to go high (up to 2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(tree_method='gpu_hist',\n",
    "                                max_bin=512,\n",
    "                                max_depth=7,\n",
    "                                n_estimators=2000)\n",
    "\n",
    "trained = XGB.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  early_stopping_rounds=200,\n",
    "                  verbose=False)\n",
    "\n",
    "optimal_n_trees = trained.best_ntree_limit\n",
    "print('Optimal number of trees: %d' % (optimal_n_trees))\n",
    "XGB.set_params(n_estimators=optimal_n_trees)\n",
    "XGB.fit(X_train, y_train)\n",
    "y_hat = XGB.predict(X_test)\n",
    "print('Accuracy of score: %.4f' % (accuracy_score(y_test, y_hat)))\n",
    "print(classification_report(y_test, y_hat, \n",
    "                            target_names = ['None', '1 or 2', '3 to 8', '9 or more']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame({'Weight': XGB.get_booster().get_score(importance_type='weight'),\n",
    "                            'Gain': XGB.get_booster().get_score(importance_type='gain'),\n",
    "                            'Cover': XGB.get_booster().get_score(importance_type='cover')},\n",
    "                           index=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_features.sort_values('Weight', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def quantile_plotter(x, y='recs', q=10, df=X_all):\n",
    "    '''Create a pointplot of y over the quantized x variable'''\n",
    "    df_small = df[[x, y]]\n",
    "    label = x + '_' + str(q) + '_quantiles'\n",
    "    df_small[label] = pd.qcut(df[x], q, duplicates='drop')\n",
    "    sns.pointplot(x=label,\n",
    "                  y=y,\n",
    "                  data=df_small,\n",
    "                  join=False)\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('reply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('commentPolarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('commentObjectivity')\n",
    "# drop in the middle (.5) is because there are many overly short comments there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('commentObjectivity',\n",
    "                 df=X[X.recognizedWordCount > 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('stdDevWordLength')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('NN_Percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('meanWordLength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('MeanIdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('commentSpellErrorsPercent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Takeaways <a name='tldr'></a>\n",
    "So what are the most important factors in predicting why some comments are upvoted and others are not. It is helpful to divide them in two tiers.\n",
    "Tier 1:\n",
    "1. **Time is of the essence!** Commenting on an article within a few hours after it is published is the most important factor in predicting popularity. Early comments have a much greater chance of snowballing in upvotes and the window of opportunity closes rather quickly with every passing hour. This is the solution to the puzzle posed in the intro: comment A appeared within an hour following the publication of the article, while comment B clocked in at 24 hours. Here is a visual based on the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('hoursAfterArticle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "It depicts the average category (with error bars) per unit of time after the publication of an article. Each unit of time here is based on 5% of the original observations of hours after the article was published before the comment appeared. The trend is clear - the sooner, the better. \n",
    "The highest average category (ie highest number of upvotes) happens within the first two hours and then total upvotes gradually decline. There is an uptick around X hours - this is due to the fact that most articles appear online slightly before midnight US Eastern Time, while most people wake up and read articles about 9-11am, so it simply reflects peak readership volume, occuring 9-10 hours later. There is not much point in posting comments roughly two days after the publication of an article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "2. Longer articles bring in more comments. Apparently commening on a longer article is associated with more upvotes on comments. There are several interpretations here. One is that readers who read longer articles tend to be more likely to comment and respond to comments. Another is that there are articles which are simply too short to be worthy of much of a response - and beyond a certain article length, it seems there isn't much of an effect. Finally, it is possible that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "quantile_plotter('articleWordCount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some feature engineering can helps us improve our predictions and learn more about the data generation process - what affects\n",
    "If we train on the full dataset, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "see if most articles are published on a certain time of day! this would explain the hump in the **hoursAfterArticle** plot.\n",
    "write a function to create a percent stacked bar against quantized feature! Run it on the full dataset for day of the week and hour of the day\n",
    "stacked histogram?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "NYTCommentsNotebook.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
